\documentclass[twoside]{article}
\usepackage{actes}


\newcommand{\coq}{{\sc Coq}}
\newcommand{\ssr}{{\sc SSReflect}}

\title{ Formalization of Mathematics : proof of the Cayley-Hamilton Theorem }

\author{Sidi Ould Biha $^1$}

\titlehead{Formalization of Mathematics}

\authorhead{Ould Biha}

\affiliation{\begin{tabular}{rr} 
\\ 1:  Inria Sophia-Antipolis,
\\     2004, route des Lucioles - B.P. 93 06902 Sophia Antipolis Cedex, France
\\     {\tt Sidi.Ould\_biha@sophia.inria.fr} 
\end{tabular}}

\begin{document}
\setcounter{page}{1}
\maketitle


\section{Introduction}
Formal proofs Systems can be very useful in the verification and validation of mathematical proofs, especially when the proofs are complex and lengthy. Recent work, as formal proof of the theorem of 4 colors~\cite{4colproof} or the theorem of prime numbers~\cite{primeth}, show that these systems have reached a level of maturity to deal with non-trivial mathematical problems. The work of formalization of mathematical theories involving a wide variety of mathematical objects requires the adoption of a similar approach to software engineering. The formalization of such theories can be seen as a development involving different components: definitions and mathematical proofs.
\paragraph*{}
A list of the 100 greatest mathematical theorems~\cite{100ths} was formed by Paul and Jack Abad. This list takes into account the place of theorem in the mathematical literature, the quality of its proof and the importance of the result he introduced. F. Wiedijk maintains a list~\cite{100th} which identifies formalizations of those theorems in some formal proofs systems. The Cayley-Hamilton theorem is in this list. This paper presents a formalization of this theorem, which is to our knowledge the first. The fact that he had not been so far formalized can be explained by the fact that it involves a lot of objects and mathematical properties of a different kind (linear algebra, multi-linear, combinatorics, etc.). These objects are not used independently; But on the contrary they fit together with each other. This work of formalization of the theorem of Cayley-Hamilton is a part of the work of formalization of the theorem of Feit-Thompson on the groups of odd order. The objectives is not only to formalize Cayley-Hamilton; but to organize the proof in reusable libraries. 
\paragraph*{}
The article is organized as follows. In section 2, we present the statement and the proof of the Cayley-Hamilton theorem. In section 3, we briefly present \ssr{}, the extension of \coq{} and platform of our development. Finally, in section 4, we present the development which was necessary to arrive at the formalization of the Cayley-Hamilton theorem.

\section{The  Cayley-Hamilton theorem}
The Cayley-Hamilton theorem can be stated~\cite{algebra} in the following way:
\begin{center}
 \textit{Any square matrix on a commutative ring satisfies its own characteristic equation.}
\end{center}
More formally, if $R$ is a commutative ring and $A$ a square matrix on $R$, then the characteristic polynomial of A, defined by: $p_{A}(x) = \det{(xI_{n} - A)}$, vanishes in A. \newline
The theorem can be stated differently by considering the endomorphisms of vector space. In this case it is not any more question of commutative ring but of field.
The proof of the Cayley-Hamilton theorem presented in~\cite{algebra} use the Cramer formula. By noting $Adj(B)$ the adjugate matrix of B (the transpose of the cofactor matrix of B), the Cramer rule states : 
\begin{equation}
  \label{Cramer}
 B * Adj{(B)} = Adj{(B)} * B =\det{(B)} * I_{n}
\end{equation}
By applying the formula (\ref{Cramer}) to the matrix $(xi_{n} - A) \in M_{n}(R[x])$, we obtain:
\begin{equation}
  \label{Cramer-mx_poly}
 Adj{(xI_{n} - A)} * (xI_{n} - A) =\det{(xI_{n} - A)} * I_{n} = p_{A}(x) * I_{n}
\end{equation}
The ring $ M_{n}(R[x])$ of the matrices of polynomials is also the ring of the polynomials with matrix coefficients $(M_{n}(R))[X]$. In $(M_{n}(R))[X] $, the equality (\ref{Cramer-mx_poly}) is written :
\begin{equation}
  \label{proof_start}
   Adj{(xI_{n} - A)} * (X - A) = p_{A}(X)
\end{equation}
This shows that $(x - A)$ is factor of $p_{A}(X)$ in $(M_{n}(R))[X] $, so $ p_{A}(A) = O_{n} $.
\paragraph*{}
To formalize a mathematical proof in a proof assistant, we need to develop this proof to be comprehensible to a computer. To reach this objective, two difficulties are to overcome. In first place, it is necessary to make explicit the parts of the proof which are implicit or `` trivial' ' for a mathematician. Paradoxically, the implementation on computer of these parts, which do not appear in the proof, is the most complex work in the formalization. In the second place, it is necessary to have statements comprehensible for a mathematician and human reader. The interest is not simply to make proof on computers but it's necessary that the statements of this proofs are nearest possible to those used in the mathematics literature. This will facilitate the re-use of this proofs in other developments.
\paragraph*{}
In the case of the Cayley-Hamilton theorem and by considering the proof above, several problems arise at the time of its formalization. To say that $M_{n}(R[x])$ is identical to $(M_{n}(R))[x]$ is algebraically equivalent to say that there is an isomorphism of ring between them. Indeed, any matrix of polynomials can be written, in a single way, as the sum of powers in $x$ multiplied by matrices, i.e. a polynomial with matrix coefficients. For example :
\begin{equation}
 \label{morphism}
 \left(
  \begin{array}{ c c }
     x^{2} + 1 & x - 2 \\
     - x + 3 & 2x - 4
  \end{array} \right)
=
 x^{2}\left(
  \begin{array}{ c c }
     1 & 0 \\
     0 & 0
  \end{array} \right) + 
x\left(
  \begin{array}{ c c }
     0 & 1 \\
     -1 & 2
  \end{array} \right) + 
\left(
  \begin{array}{ c c }
     1 & -2 \\
     3 & -4
  \end{array} \right)
\end{equation}
The formalization of this isomorphism corresponds to the writing of the function of transformation described in the example above. The properties of this morphism, which we will note $\phi$, are used implicitly in the proof. Indeed, in (\ref{Cramer-mx_poly}) the members of the equality are matrices of polynomials. The application of $\phi$ to the left and right side of the equality (\ref{Cramer-mx_poly}) gives us:
\[   \phi ( Adj{(xI_{n} - A)} * (xI_{n} - A)) = \phi ( p_{A}(x) * I_{n}) \]
The properties of morphism of $\phi$ are used to obtain:
\[       \phi ( Adj{(xI_{n} - A)}) * \phi (xI_{n} - A)  = \phi ( p_{A}(x) * I_{n}) \]
The formula (\ref{proof_start}) corresponds explicitly to the equality above.

\section{ \ssr }
\ssr~\cite{ssrman, modgrp} (for \textit{Small Scale Reflection}) is an extension of \coq{}~\cite{coqart} which introduces new tactics and \coq{} libraries adapted to work on types with an equality decidable and equivalent to the structural equality of \coq{}, called the Leibniz equality. It was initially developed by G Gonthier within the framework of its proof of the 4 colors  theorem. A development~\cite{modgrp} on the theory of finished groups was made with \ssr. This development includes, amongst other things, a formalization of the Sylow theorem and the Cauchy-Frobenuis lemma.\newline
We will present initially the method of \ssr{} to reflect between Boolean and Propositional predicates of \coq{} logic. We introduce thereafter the language of tactic of \ssr. Finally, we present some \ssr{} \coq{} libraries that we used in our development. More detailed information on \ssr{} and precisely its language of tactic can be obtained in~\cite{ssrman}.

\subsection*{Reflection}
In the \coq{} proof system, the default logic is intuitionistic. In this logic, the logical proposition and the Boolean values are distinct. \ssr{} makes it possible to combine the best of the two visions and to pass from the propositional version of a decidable predicate towards there Boolean version. The propositional version makes it possible to have structured proof whereas the Boolean makes it possible to make computation. To do this, the Boolean type is injected into the proposition type by a coercion:
\begin{verbatim}
Coercion is_true (b: bool) := b = true.
\end{verbatim}
Therefore, and transparently to the user, when \coq{} waits an object of type \texttt{Prop} and receives a value \texttt{b} of type \texttt{bool}, it will automatically translate it into the proposition \texttt{(is\_true b)}, which corresponds to the proposition \texttt{b $ = $ true}.\newline
The inductive predicate \texttt{reflect} gives a practical and comfortable equivalence between the decidable propositions and the Booleans:
\begin{verbatim}
Inductive reflect (P: Prop): bool -> Type :=
  | Reflect_true: P => reflect P true
  | Reflect_false: ~P => reflect P false.
\end{verbatim}
The proposition \texttt{(reflect P b)} indicates that \texttt{P} is equivalent to \texttt{(is\_true b)}. For example, equivalence between the Boolean conjunction \texttt{\&\&} and the propositional one \verb|/\| is given by the following lemma:
\begin{verbatim}
Lemma andP: forall a b:bool, reflect (a /\ b) (a && b).
\end{verbatim}
The lemmas of the same nature as \ texttt (andP) are defined when we want to have the equivalence between computational representation of a function (which can be calculated) and its logical representation. More details on the use of \texttt{reflect} are available in the \ssr{} documentation ~\cite{ssrman}.
\subsection*{Tactics language}
The proof scripts written with \ssr{} differ from those written using standard \coq{} tactics. The tactic language of \ssr{} facilitates the operations of interpretation and development of proof scripts. In practice, the proof scripts written with \ssr{} are more concise than those written using standard \coq{} tactics. \newline
All the frequent operations that consists in moving, splitting, generalizing formulas form (or to) the context are regrouped in the tactic \verb|move|. For example, the tactics ``\verb|move: (H1 a)|'' put, in the current goal, a instance of the hypothesis \verb|H1| for the variable \verb|a|. Another example is the tactics ``\verb|move=> x y H2|'' which corresponds to the introduction of the variables \verb|x| and \verb|y|, and a new hypothesis \verb|H2| in the current context. The tactic ``\verb|move: (H1 a) => H2 x y|'' corresponds to the combination of the above two examples in a single tactic.\newline
The tactic \verb|rewrite| combines in single command all the operations of conditional rewriting, unfolding of definition, simplifying and rewriting selecting occurrences or patterns. Those operations can be used together or separately. For example, the tactic \verb|rewrite /def H1 ?H2 !H3| unfolds the definition \verb|def|, rewrites the hypothesis \verb|H1|, rewrites zero or several times with the hypothesis \verb|H2|, and rewrites at least once with the hypothesis \verb|H3|. Another example is the tactic \verb|rewrite {2}[_ * _]H4 //| who rewrites in the second occurrence of the pattern \verb|[_ * _]| with the hypothesis \verb|H4| and simplifies the current goal. \newline
The mechanism of reflection between the decidable proposition and the boolean, described above, is integrated in the \ssr{} tactic language. For example, given a context with a hypothesis \verb|H| of type \verb|a && b|, the tactic \verb|move/andP : H => H| apply the lemma \verb|andP| to \verb|H| and introduces in the current context a new hypothesis \verb|H| of type \verb|a /\ b|. On the other hand, when the goal is like \verb|a && b|, the tactics \verb|apply/andP| replaces it by \verb|a /\ b|. Finally, when the goal is \verb|(a && b) -> G|, the tactics \verb|case/andP => H1 H2| changes it to \verb|G| and introduces two new hypothesis \verb|H1 : a| and \verb|H2 : b| in the context. 
\subsection*{Libraries }
Some Basics libraries are defined in \ssr. They consist in a hierarchy of structures to work with decidable theories and especially finished types. The structure \verb|eqType| defines the types equipped with equality decidable and equivalent to the Leibniz one. 
\begin{verbatim}
Structure eqType : Type := EqType {
  sort :> Type; 
  _ == _ :  sort -> sort -> bool; 
  eqP :  forall x y, reflect (x = y) (x == y)
}.
\end{verbatim} 
The \verb|: >| symbol declares \verb|sort| as a coercion from an \verb|eqType| to its carrier type. It the standard technique to get subtyping. The \verb|eqType| structure not only assume the existence of a decidable equality \verb|==| but also \verb|eqP| injects this equality into the Leibniz one. We can thus benefit from the power of rewriting of \coq.\newline
A major property of \verb|eqType| structures is that they give the property of \textit{proof-irrelevance} for the equality proofs of their elements. Thus there is only one proof of the equality for each pair of equal objects.
\begin{verbatim}
Lemma eq_irrelevance: forall (d: eqType) (x y: d) (E: x = y) (E': x = y), E = E'.
\end{verbatim} 
\paragraph*{}
A set on a structure of \verb|eqType| is represented by its characteristic function: 
\begin{verbatim}
Definition set (d: eqType) := d -> bool.
\end{verbatim} 
A Boolean property over an \verb|eqType| corresponds to the set of all elements which satisfy it. With this definition the set operations like the intersection or the complementary are defined by the corresponding boolean functions.
\begin{verbatim}
Definition setI (a b : set d) : set d := fun x => a x && b x.
Definition setC (a : set d) : set d := fun x => ~~ a x.
\end{verbatim}
It is useful to have a type of lists on a \verb|eqType d| to be able to define more naturally the operations which is based on a boolean test like the search of an element in a list. The type of lists on an \verb|eqType d| is defined in an inductive way by: 
\begin{verbatim}
Inductive seq : Type := Seq0 | Adds (x : d) (s : seq).
\end{verbatim}
\verb|Adds| and \verb|Seq0| correspond respectively to the constructor \verb|cons| and \verb|nil| of the \coq{} standard type \verb|list|. The type \verb|seq d| defines a list over an \verb|eqType d|. On this new type of list, functions are defined to handle and reason on its elements. The function \texttt{foldr} corresponds in \ssr{} to the operation \textit{fold} used in functional programming. The extraction operation of an element of a list is given by the function \verb|sub|. For example, \verb|sub x0 s i| return the element of index \texttt{i} in the list \texttt{s}, if \texttt{i} is strictly lower than the length of the list, and \texttt{x0} otherwise. The function \verb|mkseq| builds a list of given length from a function on the naturals. For example, \verb|mkseq f n| corresponds to the list \verb|[(f 0), (f 1), ..., (f n-1)]|.
\paragraph*{}
A finite type can be seen as a finite set. It can then be represented by the list of all its elements. The definition of finite types is based on that of \verb|seq| type. The structure \verb|finType| consist of a list on a \verb|eqType sort| and a proof that no element of this list appears more than one time.
\begin{verbatim}
Structure finType : Type := FinType {
  sort :> eqType;
  enum :  seq  sort;
  enumP :  forall x, count (set1 x) enum = 1
}.
\end{verbatim} 
In this definition \verb|(set1 x)| is the set that contains only $x$ and \verb|(count f l)| computes the number of elements \verb|y| of the list \verb|l| for which \verb|(f y)| is true. The parameter \verb|enum| corresponds to the list of the elements of the finished type. In the case of a \verb|finType d|, (\verb|enum d|) return the list of elements of \verb|d|.
\paragraph*{}
To represent the finished types of the element of the interval \(0..n-1 \), the library \ssr{} provides a family of types named \verb|ordinal| whose elements are pairs of a natural number \(p \) and a proof that \(p \) is lower than \(n \). As this proof is based on a boolean test, the property of irrelevance applies and the elements of this type are only characterized by the component \(p \). The notation \verb|I_(n)| indicates the type \verb|ordinal n|.

\section{Formalization}
In this work of formalization of the Cayley-Hamilton theorem, we use libraries on indexed operations and determinants. Those libraries were developed by Y. Bertot and G. Gonthier in the project ``Mathematical Components''. The library on the polynomials provides formalization of the algebraic properties of the polynomials, the evaluation morphism and the factor theorem. The definition of isomorphism between the ring of the matrices of polynomials and that of the polynomials of matrices is the ultimate step in the formalization of Cayley-Hamilton theorem.
\subsection{Indexed operations} 
In the definition of the operations on the matrices, for example the multiplication or the determinant, the indexed operations (sum and product) is frequent. Factorize the proof of general properties on the indexed sums and products reduces considerably the length and the complexity of the proof, and gives a more readable statements. A library for indexed operations is not only useful in the development on the matrices theory, it could be useful in developments more general than linear algebra.
\paragraph{}
An indexed operation is the generalization of the definition of a binary operation to the elements of a finite sequence. In the particular case of the addition, it is the sum of all the elements of a given sequence. \newline 
The definition of an indexed operation is given by:
\begin{verbatim}
Definition reducebig R I op nil (r : seq I) P F : R :=
  foldr (fun i x => if P i then op (F i : R) x else x) nil r.
\end{verbatim}
The parameters of the function \verb|reducebig| are : a type (not necessary an \verb|eqType|) \verb|R|, an \verb|eqType I|, a binary operation \verb|op| on \verb|R|, a element \verb|nil| of \verb|R| corresponding to the empty set, a list \verb|r| of elements of \verb|I|, a  characteristic property \verb|P| of \verb|I| (a function form \verb|I| to \verb|bool|: a set of elements of \verb|I|) and a function \verb|F| form \verb|I| to \verb|R|. The result of \verb|reducebig| corresponds schematically to: 
\[ F ~ p_{1} ~ op ~ F ~ p_{2} ~ op ~ \cdots ~ op ~ F ~ p_{n} ~ op ~ nil,  \] 
The $p_{i}$ are the elements of the list $r$ for which the property $P$ is true : the elements of the set $P$. The use of \verb|reducebig| is more natural when the operation is associative and commutative and when \verb|nil| is the neutral element of this operation. In other words, when \verb|(R, op, nil)| is a monoid. \newline
The notation \verb|\big[*%M/1]_(i|\texttt{| P i) F i} corresponds to the application of \verb|reducebig| to a monoid operation \verb|*| which has a neutral element \verb|1|. The others parameters of \verb|reducebig| are inferred implicitly by \coq. For example, \verb|\big[*%M/1]_(i|\texttt{| i < n) i} represents the mathematical standard notation $ \sum_{i<n} i$.
\paragraph*{}
A interesting lemma on \verb|reducebig| is the one who gives the usual re-indexation property. In the case of an indexed sum, this lemma corresponds to the equality between the both sums $ \sum_{i=0}^{n} (i + m)$ and $ \sum_{j=m}^{n + m} j $. To formalize this property, we consider that $i$ and $j$ are respectively of types $[0..n]$ and $[m..n+m]$ (different types), and there is a bijection between these two types. This bijection is the function $ f : x \rightarrow x + m $. \newline
The predicate \verb|ibjective P h| says that the function \verb|h| is bijective on the set {\tt P} of his domain. It is necessary for proving the re-indexation lemma.
\begin{verbatim}
Lemma reindex : forall (I J : finType) (h : J -> I) P F,
  ibijective P h ->
  \big[*%M/1]_(i | P i) F i = \big[*%M/1]_(j | P (h j)) F (h j).
\end{verbatim}
Another interesting property of indexed operations is that of the decomposition following a partition of the index set. For example and in the case of the indexed sum, this property is written $ \sum_{i=0}^{n + m} i = \sum_{i=0}^{n} i + \sum_{i=n+1}^{n + m} i $. The generalization of the property above is written in \coq{} :
\begin{verbatim}
Lemma bigID : forall (I : finType) (a : set I) (P : I -> bool) F,
  \big[*%M/1]_(i | P i) F i
    = \big[*%M/1]_(i | P i && a i) F i * \big[*%M/1]_(i | P i && ~~ a i) F i.
\end{verbatim}
In this lemma, being given a set \texttt{a}, a partition of a set \texttt{P} is the two sets $\mathtt{P \cap a}$ and $\mathtt{P \cap \bar{a} }$. The sum of the elements indexed by \texttt{P} can be decomposed into two sums of the elements indexed by these two sets.
\subsection{Canonicals Structures}
In the proof assistant \coq{}, \textit{a Canonical Structure is an instance of a record/structure type that can be used to solve equations involving implicit arguments}~\cite{coqman}. For example, to define a structure of \texttt{eqType} on the type \texttt{nat}, we have to define a decidable equality on the \coq{} naturals and proof that this equality is equivalent to the Leibniz one.
\begin{verbatim}
Fixpoint eqn (m n : nat) {struct m} : bool :=
  match m, n with
  | 0, 0 => true
  | S m', S n' => eqn m' n'
  | _, _ => false
  end.
Lemma eqnP : reflect_eq eqn.
Proof.
...
Qed.
Canonical Structure nat_eqType := EqType (@eqnP).
\end{verbatim}
The following lemma shows a simple example of use of the \texttt{Canonical Structure}.
\begin{verbatim}
Lemma eqn_add0 : forall m n:nat, (m + n == 0) = (m == 0) && (n == 0).
\end{verbatim} 
We mention that \verb|==| represents the equality in a \verb|eqType|. In the statement above \coq{} expect that \texttt{m} and \texttt{n} are of type a \verb|eqType|. But they are of type \texttt{nat}. \coq{} try to find a definition of a \verb|eqType| whose parameter \texttt{sort} is \texttt{nat}. Thanks to the definition of \texttt{Canonical Structure nat\_eqType}, \coq{} can infer automatically the type \texttt{nat\_eqType} to the arguments \texttt{m} and \texttt{n}.
\paragraph*{}
The mechanism of \texttt{Canonical Structure} is powerful and very useful in work with algebraic structure like groups or rings. \ssr{} contains a library \texttt{ssralg} which, by using this mechanism, provides a hierarchy of algebraic structures including monoid, group, ring and field. In the libraries on matrices and polynomials, we define the types of polynomials and matrices over a structures of rings. Rings structures are then defined on these types. Thereby, the same operations of rings (addition, multiplication and opposite) are used for the matrices and the polynomials. With the definition of the \texttt{Canonical Structure} on these structures, \coq{} will be able to infer automatically the structure of ring on polynomials and matrices. This enables us to have statements close to those used in standard mathematics and more readable from the point of view of the user. 
\subsection{Matrices and determinant}
A matrix on a ring $R$ is a double indexed list of coefficients. It can be seen as a function which associates a position \((i, j) \) to a value in the ring $R$. Being given $m$ and $n$ two naturals and $R$ a ring, a matrix on $R$ (an object of the type $M_{m,n}(R)$) can be represented by the following function: $ [0..n[ \rightarrow [0..m[ \rightarrow R$. To define a \texttt{eqType} on the matrices, which are functions, we need the extensionnality. The function \texttt{fgraphType} builds the graph of the functions whose domain is a \texttt{finType} and the Co-domain a \texttt{eqType}. With the definition of the graphs of functions, the functions are now equipped with a Leibniz equality. For two functions \texttt{f} and \texttt{g}, the notations \texttt{f =1 g} and \texttt{f =2 g} correspond respectively to $\mathtt{\forall x, f~x = g~x}$ and $\mathtt{\forall x~y, f~x~y = g~x~y}$. If the two functions have domain of type \texttt{finType} and co-domain \texttt{eqType}, the previous notations are equivalent to \texttt{f = g}.
The type of the matrices of size \((m, n)\) is defined by :
\begin{verbatim}
Definition matrix (m n :nat) :=
  fgraphType (I_(m) * I_(n)) R.
\end{verbatim} 
The functions \verb|matrix_of_fun| and \verb|fun_of_matrix| take respectively a function or a matrix and return a matrix or a function. The latter function is not other than a coercion from the type \texttt{matrix} to the type of functions. It enables us to say that two matrices \texttt{A} and \texttt{B} are equal if and only if we have \texttt{A =2 B}. That means that the functions associated to these matrices are equal: \texttt{fun\_of\_matrix A =2 fun\_of\_matrix B}.\newline
In the following, the notations \texttt{M\_(n)} and \verb|\Z x| correspond respectively to the type of the square matrices and the scalar matrix of \texttt{x}. The notation \verb|\matrix_(i,j) E|, where \texttt{E} is an expression of \texttt{i} and \texttt{j}, corresponds to the application of \verb|matrix_of_fun| to the function \verb|f i j => E i j|. For example the scalar matrix corresponding to an element \texttt{x} is given by the following formula:
\begin{verbatim}
Definition scalar_mx n x : M_(n) :=
  \matrix_(i, j) (if i == j then x else 0).
\end{verbatim} 
\paragraph*{}
The library on the determinants uses the formula of Leibniz to define the determinant. This choice is justified by the fact that this formula is well adapted and we have the necessary components to its formalization. In fact, a formalization of the permutations (group, signature...) was already developed in the development on the finites groups~\cite{modgrp}. Being given a square matrix $A$ of size $n$, the determinant is given by:
\begin{equation}
  \label{leibniz} \det(A)=\sum_{\sigma \in S_n} 
\epsilon(\sigma) \prod_{i=1}^n a_{i, \sigma(i)}
\end{equation} 
In this formula, it is a question of indexed sums and products, but the mathematical notations hide several other elements. In the library on the determinant, to be able to formalize the Leibniz formula (\ref{leibniz}):
\begin{itemize}
 \item the indexation of lines and columns of the matrix by naturals are replaced by an indexation by the elements of type \texttt{I\_(n)},
 \item the permutations on this finite set is described as a finite set which could be enumerated and then used as index.
\end{itemize}
\paragraph{}
With these choices, thanks to the developments on the computation of the parity of permutations and with that on the groups of permutations, the Leibniz formula (\ref{leibniz}) is written:
\begin{verbatim}
 Definition determinant n (A : M_(n)) :=
  \sum_(s : S_(n)) (-1) ^ s * \prod_(i) A i (s i).
\end{verbatim} 
The notations \verb|\sum| and \verb|\prod| respectively represent the indexed sum and the indexed product. They are instances of \verb|reducebig| for the internal operations (addition and multiplication) of the matrix coefficients ring. The notation \verb|S_(n)| represents the group of the permutations on a set with $n$ elements. In the following, the notation \verb|\det| will represent the function \verb|determinant|.
\paragraph{}
To formalize the Cramer rule, the Co-matrix of a matrix is defined using the function {\tt row'}. The latter takes in entry a number \(i\) lower than \(m\) (an element of type {\tt I\_(m)}) and a matrix of size \((m,n)\); it return the matrix of size \((m-1,n)\) where the line \(i\) was removed. With the same arguments, the function {\tt row} return the matrix of size \((1,n)\) (a line matrix) which contains the line \(i\). The transpose of the Co-matrix is represented by the function {\tt adjugate}. The Cramer rule is formally represented by the lemma \verb|mulmx_adjr|. 
\begin{verbatim}
Definition cofactor n (A : M_(n)) (i j : I_(n)) :=
   (-1) ^+(i + j) * \det (row' i (col' j A)).
Definition adjugate n (A : M_(n)) := \matrix_(i, j) (cofactor A j i).

Lemma mulmx_adjr : forall n (A : M_(n)), A * adjugate A = \Z (\det A).
\end{verbatim}
The proof uses the Laplace formula ($\det(a)=\sum_{i=1}^{n} a_{i, J} {\rm Co-matrice}_{i, j}$). This formula is formally given by : 
\begin{verbatim}
Lemma expand_determinant_row : forall n (A : M_(n)) i0,
  \det A = \sum_(j) A i0 j * cofactor A i0 j.
\end{verbatim} 
The lemma according to which the determinant is an alternate form (the determinant of a matrix, where at least two lines are identical, is null) is formally stated as follows :
\begin{verbatim}
Lemma alternate_determinant : forall n (A : M_(n)) i1 i2,
  i1 != i2 -> A i1 =1 A i2 -> \det A = 0.
\end{verbatim} 
Let's remind that the matrices are functions with two arguments. The term \verb|A i1| is a function with an argument and it corresponds to the line \verb|i1| of the matrix {\tt A}.

\subsection{Polynomials}




\begin{thebibliography}{10} 
\bibitem{100ths}
  Paul et Jack \textsc{Abad},
  \textit{The Hundred Greatest Theorems},
  Available at http://personal.stevens.edu/~nkahl/Top100Theorems.html.

\bibitem{primeth}
  Jeremy \textsc{Avigad}, Kevin \textsc{Donnelly}, David \textsc{Gray}, et Paul \textsc{Raff},
  \textit{A Formally Verified Proof of the Prime Number Theorem},
  ACM Transactions on Computational Logic, A paraître.

\bibitem{coqart}
  Yves \textsc{Bertot}, Pierre \textsc{Castéran},
  \textit{Interactive Theorem Proving and Program Development Coq'Art: The Calculus of Inductive Constructions},
  Springer Verlag,
  2004.

\bibitem{algebra}
  Nathan \textsc{Jacobson},
  \textit{Lectures in Abstract Algebra: II. Linear Algebra},
  Springer Verlag, 1975.

\bibitem{fta}
  Herman \textsc{Geuvers}, Freek \textsc{Wiedijk} et Jan \textsc{Zwanenburg},
  \textit{A Constructive Proof of the Fundamental Theorem of Algebra without Using the Rationals},
  Types for Proofs and Programs, TYPES 2000 International Workshop, Selected Papers, volume 2277 of
  LNCS, pages 96-111, 2002.

\bibitem{4colproof}
  Georges \textsc{Gonthier},
  \textit{A computer-checked proof of the four-colour theorem},
  Available at http://research.microsoft.com/~gonthier/4colproof.pdf.

\bibitem{ssrman}
  Georges \textsc{Gonthier}, Assia \textsc{Mahboubi},
  \textit{A small scale reflection extension for the Coq system},
  Available at http://www.msr-inria.inria.fr/~assia/rech-eng.html.

\bibitem{modgrp}
  Georges \textsc{Gonthier}, Assia \textsc{Mahboubi}, Laurence \textsc{Rideau}, Enrico \textsc{Tassi} et Laurent \textsc{Théry},
  \textit{A Modular Formalisation of Finite Group Theory},
  Rapport de Recherche 6156, INRIA, 2007.

\bibitem{ring-mx}
  Nicolas \textsc{Magaud},
  \textit{Ring properties for square matrices} contribution to Coq,
  http://coq.inria.fr/contribs-eng.html.

\bibitem{factor-th}
  Piotr \textsc{Rudnicki},
  \textit{Little Bezout Theorem (Factor Theorem)}, Journal of Formalized Mathematics volume 15, 2003,
  Available at http://mizar.org/JFM/Vol15/uproots.html.

\bibitem{linalg}
  Jasper \textsc{Stein},
  \textit{Linear Algebra} contribution to Coq,
  http://coq.inria.fr/contribs-eng.html.

\bibitem{coqman}
  \textsc{Coq Team},
  \textit{The Coq reference manual V 8.1},
  http://coq.inria.fr/V8.1/refman/index.html.

\bibitem{100th}
  Freek \textsc{Wiedijk},
  \textit{Formalizing 100 Theorems},
  http://www.cs.ru.nl/freek/100/.

\end{thebibliography}

\pagebreak
\thispagestyle{colloquetitle}
\cleardoublepage
\end{document}